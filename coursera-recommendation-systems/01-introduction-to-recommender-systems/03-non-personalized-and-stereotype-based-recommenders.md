# Week 2 Non-Personalized and Stereotype-Based Recommenders

## Index

* Introduction: Non-Personalized and Stereotype-Based Recommenders
* Summary Statistics
* Demographics and Related Approaches
* Product Association Recommenders
* Module Assessments
* Non-Personalized Recommenders
* Programming Non-Personalized Recommenders with LensKit

## Introduction: Non-Personalized and Stereotype-Based Recommenders

### 왜 비개인화인가?

* 새로운 사용자: 새로운 사용자에 대해서 아는 정보가 거의 없음 (cold start)
* 간단하면서도 유용함
  * 특정 아이템을 구매한 사용자의 숫자
* Online communities around common displays (e.g. Reddit, Slashdot)
  * 모든 사람들의 첫 화면은 동일함
* 개인화가 불가능한 앱이나 미디어도 존재함

**굉장히 효과적**일 수도 있음

### 출판물로써의 추천 시스템

출판물 형태의 추천시스템은 꽤나 긴 역사가 있음

* 책, 영화, 음악 리뷰
* *The New Yorker* 의 '[Goings On About Town](https://www.newyorker.com/goings-on-about-town)'
  * 뉴욕에서 열리는 이벤트들을 소개해주는 사이트
* 미슐랭(Michelin) 레스토랑 가이드: 세계 다양한 도시의 식당 추천

위의 경우에는 *편집자가 고른* 것들

* *The Negro Motorist Green-Book*
  * 미국에서 유색인종 분리 정책이 존재할 때 유색인종이 갈 수 있는 식당, 숙박시설 등을 적어놓은 책

### 집단의 의견: Zagat Survey

출판물 형태의 추천 대부분은 편집자가 만든 것인데, *Zagat Survey* 는 일반인들이 적은 식당에 대한 평가를 바탕으로 만듬

* 여러 기준에 대한 30점 만점의 평점을 제공
* 각각의 평가자의 보고서를 바탕으로 리뷰를 엮음

### 집단의 행동: Billboard

Billboard Top 200

* 판매와 라디오 재생 기록에서 산출: iTuens, record stores, etc.
* 전주의 행동에 기반하여 앨범과 곡의 상승을 보여줌: 
* 전세계의 데이터로 계산

### 그 외

* e-commerce 평점과 리뷰 요약
* 영화 박스오피스 차트
* 뉴스 사이트의 'Popular Now', 'Most Populuar' 리스트

### 약한 개인화

가끔은 사용자에 대해 약간의 정보를 아는 경우도 있음

* 우편번호나 지역
* 나이, 성별, 출신 국가, 인종 등

'*스테레오타입*' 개인화를 위한 첫 걸음

*제품 관련성(Product Association)* 은 현재 보고 있는 페이지/상품/문서 등에 기반한 추천을 가능하게 함

### 학습 목표

* 비개인화 추천의 가치와 단점에 대해서 이해한다
  * 그래서 보다 복잡한 것을 언제 사용해야하는 지 알아낼 수 있또록
* 아래의 방법을 이용해 비개인화와 약한 개인화 추천을 계산할 수 있다
  * 집계 선호도 (aggregated preferences)
  * 제품 연관성 (product association)
  * 사용자의 인구통계적 정보 (user demographic information)
* 간단한 합계와 추천 알고리즘을 이용해서 기본적인 사용자 경험을 디자인할 수 있다

## Summary Statistics 1

### Zagat Guide

* 식당을 방문한 사람들에게 설문지를 돌려서 방문한 식당에 대한 평가를 받고, 이를 직접 입력해서 데이터를 구축

### 점수 계산하기

* 어떤 의미를 가져야 하나?
  * 유명도: 사람들이 가장 많이 방문한 식당으로 점수를 매기면 프랜차이드 레스토랑이 많이 나올 수 있음
  * 평균 평점
  * 사용자가 좋아할 확률
* 계산 방법은?
  * 빈도
  * 평균
  * 보다 복잡한 방법

### Zagat Guide 점수 계산 방법

* 비밀 공식
  * Rating = `{0, 1, 2, 3}`
    * 3점은 특별한 곳이고 2점은 굉장히 좋은 식당
  * Score = `round(mean(rating) * 10)`
    * 0-30점 사이로 맞추기 위해 10을 곱함
  * 이렇게 계산하면 유명도는 고려하지 않게 됨
  * 2016년 7월 26일에 Zagat 는 별점 5개(0.1점씩 단위)로 평점 시스템을 바꿨으나 공식은 여전히 동일

### Conde Nast Traveler: 동일한 아이디어, 다른 공식

* 다양한 카테고리에 대해 0-100점 사이의 값을 보여줌
* 사용자들에게 `매우 나쁨, 나쁨, 보통, 좋음, 매우 좋음` 에 대해 평가를 매기게 하고 `매우 좋음, 좋음` 의 비율을 계산해서 이를 가지고 평점을 매김
* 두 방법에 대한 메리트
  * `좋음` 과 `나쁨` 을 처리하는 방법: `나쁨`  이 나온 경우 점수를 깎을 수도 있고, `좋음` 에 대해서만 점수를 매길 수도 있음

### Amazon 고객 리뷰

* 평균 평점도 보여주고 평점의 분포도, 평가한 사용자 수를 함께 보여줌

### 뜯어보기

* 유명도는 중요한 평가 지표
* 평균 평점은 가끔 잘못된(misleading) 정보를 알려줄 수도 있음
  * 좋아한 사람들의 비율을 합계(summing) 해서 조정할 수 있음
  * 사용자의 평점을 정규화(normalize) 해서 조절할 수 있음
    * 정규화를 하면 평점의 척도가 달라짐
    * 어떤 사람들은 평점에 조금 후할 수 있고, 어떤 사람은 조금 짤 수 있기 때문에 두 집단을 동일한 스케일로 놓고 보면 오독할 수도 있음
  * 평가자의 신용도를 고려해볼 수도 있음 (이전의 평가들을 살펴봐야함)
* 데이터가 많을수록 좋다... 어느 정도 까지는
  * 평균, 빈도, 분포

### 빠진 건 없을까

* 사용자에 대한 정보
  * 30대 남성이 유명한 새로 나온 노래를 찾는다고 했을 때 15살 여성들 사이에서 유명한 노래를 추천해준다면...
* 사용자의 맥락
  * 아이스크림 선데에 올릴 소스를 찾는데 케찹이 가장 잘 나가는 소스라고 그걸 추천해주면...

### Zagat 로 돌아와서

* 서비스가 나빠졌다고 하는 사용자들이 늘어나고 있는데 왜 그럴까
  * 평범한 식당의 평점이 높게 나옴
  * 좋은 식당의 평점이 보통으로 나옴
* 무슨 일이지
  * 자기선택 편향
    * 처음 방문했을 때의 경험이 좋지 않았다면 재방문을 하지 않을 것이고 이로 인해 낮은 점수를 주는 사람들이 점점 적어져서 그 식당의 점수가 높아짐
  * 평가자의 다양성이 늘어남
    * 사람들의 입맛이 달라짐. 처음에는 운영자의 친구였기 때문에 취향이 비슷했으나 지금은 사용자가 많아져서 보다 다양한 취향이 생김

### 배워가야할 것들

* 비개인화 유명도 통계나 평균들은 적절하게 사용하면 효과적일 수 있음
  * 평균과 사용자의 필요도 사이의 관계를 잘 이해해야함
* 많은 경우에 빈도와 평균, 그리고 분포를 함께 보여주면 가장 좋음
* 순위를 매기는 경우 평균 대신에 특정 점수 이상을 매긴 사용자의 비율을 보여주는 것도 좋음
  * 또는 특정 점수 이하
* 개인화를 통해 여러 제약을 극복할 수 있음

## Summary Statistics 2

### 시작하기

* 지난 두 강의에서는
  * 데이터 수집 방법
  * 사용자에게 무엇을 보여줄지 정하기 - 예측값, 추천 리스트
* 이번 강의에서는: 이를 적용하는 방법
  * 어떤 예측에 대해 보여줄지
  * 순위를 매기는 방법

### Summary Statistics 2: 학습 목표

* 예측값을 계산하고 보여주는 여러가지 방법을 이해한다
* Sparse 하고 시간에 따라 바뀌는 데이터를 가진 아이템의 순의를 매기는 방법을 이해한다
  * Sparse: 아이템은 엄청나게 많은 데에 반해 사용자들의 평가(explicit or implicit) 는 적은 경우
* 예측과 추천을 위한 디자인 공간에서의 요점과 여기서의 트레이드 오프(tradeoff) 에 대해서 이해한다

### 보여주는 목적

> 사용자들이 아이템을 사거나, 읽거나, 보는 결정을 도와주기 위해

### 선호도를 집계하여 보여주는 방식 (예측)

* 단순하게 보여주는 방식
  * 평균 점수 $= \frac{sum(Ratings)}{n(Ratings)}$
  * upvote 비율 $= \frac{n(Upvotes)}{n(votes)}$
    * 평점을 매긴 사람들이 아이템을 좋아했는가?
    * 점수나 비율만 있으면 유명도(몇 명이나 평점을 매겼는지)를 알 수 없음
  * 순 upvote $= n(Upvote) - n(Downvote)$
  * `좋아요` 수
    * 유명도(몇 명이나 참여했는지)를 알 수 있음
    * 반대의 의견을 알 수 없음
  * 전체 평점 중 별점 4점(긍정적인) 이상의 비율 $= \frac{n(Ratings >= 4)}{n(Ratings)}$
  * 전체 별점 분포: 1점 (10%), 2점 (15%), 3점 (25%), 4점 (30%), 5점 (20%)
    * 복잡함

### 아이템 순위 매기기 (추천)

* 예측 점수로 순위를 매기지 않는 이유
  * 평점은 높은데 갯수가 적을 수 있음
  * 점수가 다변량일 수도 있음 (?)
  * Domain 이나 비즈니스가 고려되어야할 수 있음
    * 아이템이 오래됐거나
    * 아이템이 '선호하지 않는' 다거나

### 순위에서의 고려 사항들

* 신뢰도
  * 이 아이템이 좋다는 것에 어느 정도 자신이 있는가?
    * 많은 평가를 받은 4점짜리 아이템이 하나의 평가만 받은 5점짜리 보다는 신뢰도가 높음
* 위험 감수 정도
  * 높은 위험을 감수하고 과감하게 추천을 할 것인가
  * 보수적으로 추천을 할 것인가
* Domain이나 비즈니스의 고려 사항
  * 나이
  * 추천 시스템의 목표

### Damped means

* 문제: 평점 갯수가 적을 때에는 신뢰도가 낮아짐
* 해결책: 모든 것이 평균이라고 가정
* 평점이란 비평균의 증거
* $k$ 는 필요한 증명의 강도
  * $damped \ mean = \frac{\sum_ur_{ui} + k\mu}{n+k}$
  * $u$: user
  * $r_{ui}$: user $u$'s rating on item $i$
  * $\mu$: 전체 시스템에서의 모든 평점의 평균

### 신뢰구간 (Confidence Interval)

* 신뢰구간의 한계는 위험과 신뢰도에 영향을 줌
  * 신뢰 하한(Lower bound of ci) 은 보수적: 좋다는 것을 확신
  * 신뢰 상한(Upper bound of ci) 은 위험이 있음: 놀라울 가능성이 존재
* Reddit 은 댓글을 평가하는 데에 Wilson interval(이항분포)을 사용함

### Domain Consideration: 시간

* Reddit: 오래된 이야기는 더이상 흥미롭지 않음
  * 비록 Upvote 가 많다고 하더라도!
* eBay: 아이템은 수명이 짧다

### [Hacker News: 새 글 점수 매기기](https://medium.com/hacking-and-gonzo/how-hacker-news-ranking-algorithm-works-1d9b0cf2c08d)

* $Score = \frac{(U - D - 1)^\alpha}{(t_{now} - t_{post})^\gamma} \times P$
* 순 upvote (Upvote - Downvote - 1) 은 시간에 따라 감소함
  * $\alpha = 0.8$
  * 투표수가 많은 글에 최근에 투표한 것의 효과를 줄여서 최근에 올린 흥미로운 글이 예전의 유명한 글보다 우선적으로 나오게 만들기 위함
* 오래된 아이템은 투표에 의해서만 점수가 매겨짐
  * $age = t_{now} - t_{post}$ (시간)
  * gravity: $\gamma = 1.8$
  * 값이 기하급수적으로 감소하기 때문에 일정 시간이 지난 글들의 경우 경과 시간에 따른 차이는 그리 크지 않지만, 상대적으로 최근에 올라온 글의 경우 경과 시간이 조금만 차이가 나도 그 값이 크게 달라짐
* 아이템 페널티항 ($P$) 를 곱해줌
  * 커뮤니티 목표(비지니스 규칙) 를 점수에 포함하기 위함

### [Reddit: 점수 매기기 (2010)](https://medium.com/hacking-and-gonzo/how-reddit-ranking-algorithms-work-ef111e33d0d9)

* $Score = log_{10}(max(1, |U-D|) + \frac{sign(U-D) \times t_{post}}{45000}$
  * 투표 수에 log 변환 적용
    * decrease marginal value of later votes
  * 레딧에서의 시간은 초(second) 단위
  * Downvote 이 더 많은 아이템은 사라짐
  * Time vs vote impact independent of age
  * 뉴스 아이템은 점수를 매기지만 코멘트는 점수를 매기지 않음

### 랭킹 Wrap-up

* 이론에 기반을 둔 방법들도 존재 (신뢰 구간, damping, log, decaying term)
* 많은 사이트들이 추가적인 방법을 사용함
* 많은 공식들이 상수항을 가지고 있으며, 서비스에 크게 영향을 받음
* '좋게' 또는 '나쁘게' 조정할 수 있음
* Domain 특성과 목표에 기반하여 만들어야 함

### 복잡한 점수로 예측하기?

* 이론적으로는 괜찮은 방법
* 투명성과 이해가능성에 주의해야함
  * damped mean 을 '평균 평점' 이라고 하면 사용자들은 헷갈릴 수 있음
  * (평점 갯수가 별로 없는 경우에는) 대부분의 중요한 경우에는 직접 확인하는 것이 가장 쉬움

### 결론

* 희소성(sparsity), 불일치성(inconsistency), 시간적인 고려(temporal concerns) 등은 데이터를 더럽게 만듬
* 간단한 점수 매기는 방법은 domain 이나 비즈니스의 요구에 꼭 맞지는 않음
* 이를 해결하는 좋은 방법들이 존재함 (decay, time, penalties, damping)
* 이후엔 normalization 방법에 대해 알아보려고 함

## Demographics and Related Approaches

### Demographics: What and Why?

* 동기
  * 유명도가 개인의 취향을 대표하지는 못함
  * 다른 취향을 가진 코호트로 이걸 찾을 수 있지 않을까?
    * 연령, 성별, 인종/국가, 사회경제적 상태, 교육 정도, 수입, 위치 등
  * 예측할 수 있는 비인구통계학적인 것들

### OK, But How?

* 사용 가능한 인구통계학 정보(또는 이와 관련된 것들) 로 시작하기
  * 많은 것들이 전처리나 등급 나누기(bucketing) 를 요구함
    * 연령을 연령대로 나눈다거나
    * 우편번호를 사회경제적 상태, 도시/시골, 주요 인종 등으로 바꿀 수도 있음
* 그런 뒤 데이터가 인구통계학 정보와 상관관계를 보이는 것을 찾아야함
  * 산점도, 상관관계, ...
  * 깊은 분석을 하는 건 아니고 전반적인 관계를 보는 용도

### If you find Relevent Demographics

* Step 1: 인구통계 정보로 요약 통계량 살펴보기
  * e.g., 성별에 따라 가장 유명한 아이템 찾아보기
  * Factorial Design: (연령대 x 성별) 45-60세 사이의 남성들 사이에서 가장 유명한 아이템
* Step 2: 다중회귀모형 고려해보기
  * 인구통계적 정보에 기반하여 아이템 예측해보기
    * 연속형 데이터(평점 등)에는 선형 모형을 사용해본다거나
    * Binary 데이터(구매, 시청 여부 등)에는 로지스틱 회귀 모형을 사용해본다거나

### Important!

* 알려지지 않은 인구통계적 정보에 사용할 기본값(default) 을 설정해야함
  * 간단하게는 전체적인 선호도로할 수 있음
  * 새로운 방문자의 기대 인구통계정보를 반영할 수도 있음: 최근에 20대가 많이 들어왔다면 정보가 없는 사람을 20대라고 생각하자
  * 별도로 모델링을 할 수도 있음
* 만약 인구통계적 정보가 유용했다면 사용자로부터 이러한 데이터를 얻는 것이 핵심
  * 다양한 곳에서 얻을 수 있음: 광고 네트워크, 멤버십, 설문 등
  * 어떤 경우에는 인구통계적 정보를 데이터로부터 "예측"할 수도 있음

### The Power and Limits of Demographics

* 많은 경우 인구통계학적 정보로 효과를 얻을 수 있는데, 제품이나 컨텐츠가 그 사람들에게 도달하기 위해 만들어졌기 때문
  * 텔레비전 프로그램
  * 잡지 기사나 광고
  * 개인적인 제품
* 또는 제품 자체가 자연스럽게 다른 그룹에 비해 특정 그룹에게 매력적일 수도 있음
* 하지만 일반적인 인구통계학적 그룹의 선호도와 다른 취향을 가진 사람들에게는 끔찍한 실패를 하기도 함

## Product Association Recommenders

### People Who Like/Bought/...

* 아마존에서 특정 제품을 보고 있으면 아래에
  * 이 제품을 본 고객들은 이런 제품들도 샀습니다
  * 이 제품을 산 고객들은 이런 제품들도 같이 샀습니다

### Ephemeral, Contextual Personalization

* "현재 사용자가 하고 있는 것" 에 초점이 맞춰짐
  * 사용자가 현재 보고 있는 것이 사용자의 현재의 흥미를 반영한다
    * ephemeral: 장기적으로 지속적이지 않고 일시적임
    * contextual: 현재 하고 있는 것에 귀속되어 있음
  * 하지만 사용자의 장기적인 취향을 반영하지는 않음

### How to Compute?

* Version 1: Manual Corss-Sell Tables
  * 마케터들이 수집한 교차 판매 또는 추가 판매(up-sales) 를 반영하여 생성
* Version 2: Data Mining Associations
  * 어떤 것을 찾고 있는가?
    * 현재 context 에서 구매될 가능성이 가장 높은 것?
    * 현재 context 에서 "같이 구매될 가능성"이 가장 높은 것?

### Start Simple

* Start Simple: X 를 구매한 사람들 중 Y 도 구매한 사람의 비율을 아래와 같이 구할 수 있음
  * $\frac{X \cap Y}{X}$
  * 직관적으로는 맞으나 실제로 유용한가? 만약에 X 가 멸치 페이스트이고 Y 가 바나나라면?
    * 바나나는 이미 많은 사람들이 사는 제품이기 때문에 멸치 페이스트와 관련이 없을 수 있음
    * 시저 드레싱을 만들기 위해 마늘을 사는 경우라면 가능한 것 같음
  * 난관: Y 의 전체적인 유명도를 고려하지 않음

### Bayes' Law

* $P(A|B) = \frac{P(B|A)P(A)}{P(B)}$
* 이전에 비해 Y 가 어떻게 바뀌었을까:
  * $\frac{P(Y|X)}{P(Y)}$: X 를 샀을 때 Y 를 살 확률 $\div$ Y 를 살 확률

### Other solutions ...

* 연관 규칙 마이닝 (Association rule mining) 은 리프트 메트릭을 이용함
  * $\frac{P(X \cap Y)}{P(X) \times P(Y)}$
    * 방향이 없는 (non-directional) 규칙
    * 보다 일반적으로 연관 규칙은 각각의 제품이 아닌 장바구니에 든 제품들을 살펴봄

### Association Rules in Practice

* The beer and diapers story
  * 각각의 제품을 사는 것보다 둘을 같이 사는 경우가 많았다는 이야기가 있기는 함
* Not just products - Link Association
  * 뉴스 사이트에서 어떤 경로를 통해 왔는지를 통해 기사 추천을 하기도 함
* Sports cars and leather driving gloves
  * 방향이 있는 규칙
  * 이미 비싼 아이템을 사는 경우라면 적당한 가격의 제품을 추가로 팔 수도 있음
  * 디자인만 잘 한다면 반대 방향도 가능하기도 함
* Are all recommendations worth making?
  * Business rules
  * 재고가 있는 제품만 추천, 미끼 상품은 추천하지 않음

### Some take-away lessons

* 제품 연관 추천시스템은 보다 관련된 추천을 제공하기 위해 현재의 맥락을 이용
  * 현재 제품, 경로, 링크 등
* 이전의 거래 내역으로부터 제품 연관을 연산할 수 있음
  * 높은 확률(유명한 것)과 증가된 확률 사이의 균형
  * 절대적인 규칙은 없고 비지니스에에서의 결정이 필요
* 이러한 추천 시스템은 추가 또는 대체 판매에 이용할 수 있음
